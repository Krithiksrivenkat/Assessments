# -*- coding: utf-8 -*-
"""LVADSUSR161_ia2_krithiksri_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U2lOnlfC556HoAHSLGIGJR7_DiikC2jz
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score
from sklearn.preprocessing import MinMaxScaler


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv("winequality-red.csv")
df.head(3)

#1.5)tasks
#A)handling missing values
df.isnull().sum()

for i in df.select_dtypes(include='number').columns:
  mean=df[i].mean()
  df[i]=df[i].fillna(mean)

df.isnull().sum()

#handling outliers
for i in df.select_dtypes(include='number').columns:
  sns.boxplot(x=df[i])
  plt.show()

for i in df.select_dtypes(include='number').columns:
  q1=df[i].quantile(0.25)
  q3=df[i].quantile(0.75)
  iqr=q3-q1
  lower=q1-1.5*iqr
  upper=q3+1.5*iqr
  df[i]=df[i].clip(lower=lower,upper=upper)
  sns.boxplot(x=df[i])
  plt.show()

#B)Data transformation
df['quality'].value_counts()
df.loc[df['quality']<=6,'quality']=0
df.loc[df['quality']>6,'quality']=1

df['quality'].value_counts()

#C)Encoding and balancing data
#the data has numerical data so encoding not needed

#D)feature selection
correlation=df.corr()
sns.heatmap(correlation,annot=True,fmt='.2f',cmap='coolwarm')
plt.show()

#duplicate analysis
df.duplicated().sum()
df.drop_duplicates(inplace=True)

df.duplicated().sum()

#E)data splitting
x=df.drop(columns=['quality'])
y=df['quality']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=43)

#scaling data
scale=MinMaxScaler()
x_train_scaled=scale.fit_transform(x_train)
x_test_scaled=scale.transform(x_test)

#F)model development
model1=RandomForestClassifier(n_estimators=100,random_state=43)
model1.fit(x_train_scaled,y_train)

y_pred=model1.predict(x_test)

print("accuracy score:\n",accuracy_score(y_test,y_pred))
print("precision score:\n",precision_score(y_test,y_pred))
print("recall score:\n",recall_score(y_test,y_pred))

model2=KNeighborsClassifier(n_neighbors=3)
model2.fit(x_train_scaled,y_train)

y2=model2.predict(x_test_scaled)

print("accuracy score:\n",accuracy_score(y_test,y2))
print("precision score:\n",precision_score(y_test,y2))
print("recall score:\n",recall_score(y_test,y2))